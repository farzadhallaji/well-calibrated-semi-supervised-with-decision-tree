{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = {'1':'r', '2':'g', 'Iris-virginica':'b'}\n",
    "\n",
    "# # fig, ax = plt.subplots()\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d') \n",
    "# for i in range(len(X_train)):\n",
    "#      ax.scatter(X_train[i][5] ,X_train[i][1], X_train[i][2],color=colors[Y_train[i]] , s=50, alpha=0.6, edgecolors='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library ðŸ˜š\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config ðŸ˜š\n",
    "path_to_datasets = '/home/farzad/Desktop/semiWithTree/originDataset/'\n",
    "dataset_name = 'bupa'\n",
    "\n",
    "\n",
    "dataset_path  = path_to_datasets + dataset_name\n",
    "base_classifier = DecisionTreeClassifier\n",
    "random_state = 0\n",
    "min_samples_leaf=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_xy(test_data):\n",
    "    # assert : class = last atr ðŸ˜š\n",
    "    x_test = test_data.values[:, 0:-1]\n",
    "    y_test = (test_data.values[:, -1]).astype('int')\n",
    "    \n",
    "    return x_test,y_test\n",
    "\n",
    "def read_data(dataset_path) :\n",
    "    \n",
    "    train_raw_data = loadarff(dataset_path+'/train.arff')\n",
    "    test_raw_data = loadarff(dataset_path+'/test.arff')\n",
    "    \n",
    "    train_data = pd.DataFrame(train_raw_data[0])\n",
    "    test_data = pd.DataFrame(test_raw_data[0])\n",
    "    \n",
    "    train_data['Class'] = train_data['Class'].astype(int)\n",
    "    test_data['Class'] = test_data['Class'].astype(int)\n",
    "    \n",
    "    return train_data,test_data\n",
    "\n",
    "\n",
    "def get_rate_p(train_y) : \n",
    "    \n",
    "    counter=collections.Counter(train_y)\n",
    "    tuple_list_pn = counter.most_common()\n",
    "    \n",
    "    return tuple_list_pn[0][1]/(tuple_list_pn[0][1]+tuple_list_pn[1][1]) , tuple_list_pn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int([1 , 2.0])\n",
    "# # int(b'1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data,test_data = read_data(dataset_path)\n",
    "# # (train_x,train_y),(test_x , test_y) \n",
    "# counter=collections.Counter(train_y)\n",
    "# a=counter.most_common()\n",
    "# a[0][1]/a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trainset(train_data) :\n",
    "    \n",
    "    labeled , unlabeled = [],[]\n",
    "    \n",
    "    size_dataset = len(train_data)\n",
    "    train_x,train_y = divide_xy(train_data)\n",
    "    \n",
    "    rate_p , tuple_list_pn = get_rate_p(train_y)\n",
    "    \n",
    "    size_labeled_data = round(0.1 * size_dataset)\n",
    "    size_unlabeled_data = size_dataset - size_labeled_data\n",
    "    \n",
    "    size_labeled_p_data = round(rate_p*size_labeled_data)\n",
    "    size_labeled_n_data = size_labeled_data - size_labeled_p_data\n",
    "    \n",
    "    labeled_index = []\n",
    "    unlabeled_index = []\n",
    "    selected_pl = 0\n",
    "    selected_nl = 0\n",
    "    \n",
    "    for i,cls in enumerate(train_y):\n",
    "        # if data point class's == 0 ðŸ˜š\n",
    "        if cls == tuple_list_pn[0][0] :\n",
    "            if selected_pl < size_labeled_p_data :\n",
    "                labeled_index.append(i)\n",
    "                selected_pl+=1\n",
    "            else :\n",
    "                unlabeled_index.append(i)\n",
    "        else :\n",
    "            if selected_nl < size_labeled_n_data :\n",
    "                labeled_index.append(i)\n",
    "                selected_nl+=1\n",
    "            else :\n",
    "                unlabeled_index.append(i)\n",
    "                \n",
    "    for i in labeled_index:\n",
    "        labeled.append(train_data.values[i])\n",
    "    \n",
    "    for i in unlabeled_index:\n",
    "        unlabeled.append(train_data.values[i])\n",
    "    \n",
    "#     print(size_dataset , size_labeled_data , size_unlabeled_data)\n",
    "#     print(rate_p , tuple_list_pn)\n",
    "#     print(size_labeled_p_data , size_labeled_n_data)\n",
    "#     print(selected_pl/(selected_pl+selected_nl),selected_pl, selected_nl)\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(labeled,columns=train_data.columns),pd.DataFrame(unlabeled,columns=train_data.columns),rate_p,tuple_list_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(base_classifier, labeled_data, test_data):\n",
    "\n",
    "    labeled_x,labeled_y = divide_xy(labeled_data)\n",
    "    test_x,test_y = divide_xy(test_data)\n",
    "\n",
    "    # dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    dtree=base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\n",
    "    dtree.fit(labeled_x,labeled_y)\n",
    "    \n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(dtree, out_file=dot_data,filled=True, rounded=True,special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    img = Image(graph.create_png())\n",
    "    \n",
    "    y_pred = dtree.predict(test_x)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(test_y, y_pred)\n",
    "    \n",
    "    return accuracy , img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data,test_data = read_data(dataset_path)\n",
    "# labeled_data , unlabeled_data , rate_p,tuple_list_pn = split_trainset(train_data)\n",
    "# # (train_x,train_y),(test_x , test_y) \n",
    "# unlabeled_data.at[1, 'Class'] = 0\n",
    "# pd.concat([labeled_data , pd.DataFrame([unlabeled_data.values[1]] , columns=labeled_data.columns)] , ignore_index=True)\n",
    "# # labeled_data\n",
    "# # unlabeled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def confidency(name , DTclassifier , labeled_data , unlabeled_data , i , confidence) :\n",
    "\n",
    "    test_x,test_y = divide_xy(unlabeled_data)\n",
    "    is_confident = False\n",
    "    lbl = DTclassifier.predict([test_x[i]])\n",
    "    if name == 'Probability' :\n",
    "        i_confidence = DTclassifier.predict_proba([test_x[i]])\n",
    "        if max(i_confidence[0]) > confidence :\n",
    "            is_confident = True\n",
    "    \n",
    "    return is_confident , lbl\n",
    "\n",
    "\n",
    "def selection_metric(labeled_data,unlabeled_data ,rate_p,tuple_list_pn , confidence,selection_rate , confidence_method_name) :\n",
    "    \n",
    "    labeled_x,labeled_y = divide_xy(labeled_data)\n",
    "    unlabeled_x,unlabeled_y = divide_xy(unlabeled_data)\n",
    "\n",
    "    # dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    DTclassifier = base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\n",
    "    DTclassifier.fit(labeled_x,labeled_y)\n",
    "    \n",
    "    removed_selected_data = unlabeled_data.copy()\n",
    "    total_selected_labeling = pd.DataFrame(columns=labeled_data.columns)\n",
    "    selected_labeling = pd.DataFrame(columns=labeled_data.columns)\n",
    "    selected_index = []\n",
    "    selected_y = []\n",
    "    \n",
    "    \n",
    "    for i  in range(len(removed_selected_data)) :\n",
    "        is_confident , lbl = confidency(confidence_method_name , DTclassifier , labeled_data ,\n",
    "                                        removed_selected_data , i , confidence)\n",
    "        if is_confident: \n",
    "            selected_index.append(i)\n",
    "            selected_y.append(lbl[0])\n",
    "            # set class\n",
    "            removed_selected_data.at[i, 'Class'] = lbl[0]\n",
    "\n",
    "            \n",
    "    \n",
    "    selected_index_p = []\n",
    "    selected_index_n = []\n",
    "    \n",
    "    \n",
    "    size_selected  = round(selection_rate * len(labeled_data))\n",
    "    print(' PISH FARZ  size_selected : ', size_selected)\n",
    "    \n",
    "    #should be constant rate \n",
    "    new_rate_p,new_tuple_list_pn = get_rate_p(np.array(selected_y))\n",
    "        \n",
    "    len_new_selected_p = new_tuple_list_pn[0][1]\n",
    "    len_new_selected_n = new_tuple_list_pn[1][1]\n",
    "    \n",
    "    len_lebeled_p = tuple_list_pn[0][1]\n",
    "    len_lebeled_n = tuple_list_pn[1][1]\n",
    "\n",
    "    size_select_p = 0\n",
    "    size_select_n = 0\n",
    "    \n",
    "    \n",
    "    print('rate_p:',rate_p , '  new_rate_p:',new_rate_p)\n",
    "    print('tuple_list_pn:',tuple_list_pn , '  new_tuple_list_pn:',new_tuple_list_pn)\n",
    "    \n",
    "    if new_rate_p > rate_p :\n",
    "        size_select_n = round(min(len_new_selected_n , size_selected * (1-rate_p)))\n",
    "        size_select_p = round(size_select_n * (rate_p/(1-rate_p)))\n",
    "        size_selected = size_select_n + size_select_p\n",
    "            \n",
    "    else :\n",
    "        size_select_p = round(min(len_new_selected_p , size_selected * rate_p))\n",
    "        size_select_n = round(size_select_p * ((1-rate_p)/rate_p))\n",
    "        size_selected = size_select_n + size_select_p\n",
    "\n",
    "            \n",
    "        \n",
    "    print('size_select_p : ' , size_select_p , '   size_select_n : ' , size_select_n, '   size_selected : ' , size_selected)\n",
    "    \n",
    "    \n",
    "    p = new_tuple_list_pn[0][0]\n",
    "    \n",
    "    i=0\n",
    "    while(size_select_p > 0):\n",
    "        if selected_y[i] == p :\n",
    "            selected_index_p.append(i)      \n",
    "            size_select_p-=1\n",
    "        i+=1\n",
    "                \n",
    "    i=0\n",
    "    while(size_select_n > 0):\n",
    "        if selected_y[i] != p :\n",
    "            selected_index_n.append(i)  \n",
    "            size_select_n-=1\n",
    "        i+=1\n",
    "        \n",
    "    print('selected_index_p : ',len(selected_index_p))\n",
    "    print('selected_index_n : ',len(selected_index_n))\n",
    "    \n",
    "    \n",
    "    for i in range(len(selected_index_p)):\n",
    "        selected_labeling=selected_labeling.append(removed_selected_data.iloc[selected_index_p[i]] ,ignore_index=True)\n",
    "    print('selected_labeling_p: ', len(selected_labeling))\n",
    "        \n",
    "    for i in range(len(selected_index_n)):\n",
    "        selected_labeling=selected_labeling.append(removed_selected_data.iloc[selected_index_n[i]] ,ignore_index=True)\n",
    "    print('selected_labeling_n: ', len(selected_labeling))\n",
    "\n",
    "    removed_selected_data.drop(removed_selected_data.index[selected_index])\n",
    "    \n",
    "    total_selected_labeling = pd.concat([labeled_data ,selected_labeling],ignore_index=True)\n",
    "    \n",
    "    return total_selected_labeling,removed_selected_data\n",
    "\n",
    "\n",
    "def self_labeling(labeled_data , unlabeled_data , iteration , rate_p,tuple_list_pn , confidence,selection_rate,confidence_method_name):\n",
    "\n",
    "    \n",
    "    labeled_unlabel_data = labeled_data.copy()\n",
    "    removed_selected_data = unlabeled_data.copy()\n",
    "    \n",
    "    while iteration:\n",
    "        \n",
    "        selected_labeling,removed_selected_data = selection_metric(labeled_unlabel_data,removed_selected_data,\n",
    "                                                                   rate_p,tuple_list_pn ,\n",
    "                                                                   confidence,selection_rate,\n",
    "                                                                   confidence_method_name)\n",
    "        labeled_unlabel_data = pd.concat([labeled_unlabel_data , selected_labeling])\n",
    "        \n",
    "        print('iteration:' , iteration , ' , selected_labeling:' , len(selected_labeling)\n",
    "             , ' , labeled_data:' , len(labeled_data))\n",
    "        iteration-=1\n",
    "        \n",
    "    return labeled_unlabel_data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate_p :  0.5775862068965517\n",
      " PISH FARZ  size_selected :  92\n",
      "rate_p: 0.5775862068965517   new_rate_p: 0.8206896551724138\n",
      "tuple_list_pn: [(2, 134), (1, 98)]   new_tuple_list_pn: [(2, 119), (1, 26)]\n",
      "size_select_p :  36    size_select_n :  26    size_selected :  62\n",
      "selected_index_p :  36\n",
      "selected_index_n :  26\n",
      "selected_labeling_p:  36\n",
      "selected_labeling_n:  62\n",
      "iteration: 1  , selected_labeling: 85  , labeled_data: 23\n",
      "0.6106194690265486 0.6283185840707964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    train_data,test_data = read_data(dataset_path)\n",
    "    train_x,train_y = divide_xy(train_data)\n",
    "    test_x , test_y = divide_xy(test_data)\n",
    "    \n",
    "    labeled_data,unlabeled_data , rate_p,tuple_list_pn = split_trainset(train_data)\n",
    "    \n",
    "    a1 , img1 = evaluate_classifier(base_classifier , labeled_data  , test_data)\n",
    "    \n",
    "    total_labeled_data = self_labeling(labeled_data , unlabeled_data , 1, \n",
    "                                       rate_p,tuple_list_pn ,\n",
    "                                       confidence=0.9,selection_rate = 4,confidence_method_name='Probability')\n",
    "    \n",
    "    a2 , img2 = evaluate_classifier(base_classifier , total_labeled_data  , test_data)\n",
    "    \n",
    "    print(a1 , a2)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1,2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>91.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>87.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>98.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>91.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>79.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>89.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>89.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>86.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>88.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>92.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>92.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    attribute_0  attribute_1  attribute_2  attribute_3  attribute_4  \\\n",
       "0          85.0         92.0         45.0         27.0         31.0   \n",
       "1          88.0         62.0         20.0         17.0          9.0   \n",
       "2          88.0         67.0         21.0         11.0         11.0   \n",
       "3          92.0         54.0         22.0         20.0          7.0   \n",
       "4          90.0         60.0         25.0         19.0          5.0   \n",
       "5          89.0         52.0         13.0         24.0         15.0   \n",
       "6          90.0         64.0         61.0         32.0         13.0   \n",
       "7          86.0         77.0         25.0         19.0         18.0   \n",
       "8          89.0         67.0         23.0         16.0         10.0   \n",
       "9          94.0        116.0         11.0         33.0         11.0   \n",
       "10         85.0         64.0         59.0         32.0         23.0   \n",
       "11         91.0         78.0         34.0         24.0         36.0   \n",
       "12         87.0         70.0         12.0         28.0         10.0   \n",
       "13         98.0         55.0         13.0         17.0         17.0   \n",
       "14         91.0         72.0        155.0         68.0         82.0   \n",
       "15         85.0         54.0         47.0         33.0         22.0   \n",
       "16         79.0         39.0         14.0         19.0          9.0   \n",
       "17         84.0         92.0         68.0         37.0         44.0   \n",
       "18         89.0         68.0         26.0         39.0         42.0   \n",
       "19         89.0        101.0         18.0         25.0         13.0   \n",
       "20         86.0         84.0         18.0         14.0         16.0   \n",
       "21         88.0         61.0         19.0         21.0         13.0   \n",
       "22         92.0         56.0         14.0         16.0         10.0   \n",
       "23         92.0         59.0         35.0         13.0         19.0   \n",
       "\n",
       "    attribute_5  Class  \n",
       "0           0.0    1.0  \n",
       "1           0.5    1.0  \n",
       "2           0.5    1.0  \n",
       "3           0.5    1.0  \n",
       "4           0.5    1.0  \n",
       "5           0.5    1.0  \n",
       "6           0.5    1.0  \n",
       "7           0.5    1.0  \n",
       "8           0.5    1.0  \n",
       "9           0.5    1.0  \n",
       "10          0.0    2.0  \n",
       "11          0.0    2.0  \n",
       "12          0.0    2.0  \n",
       "13          0.0    2.0  \n",
       "14          0.5    2.0  \n",
       "15          0.5    2.0  \n",
       "16          0.5    2.0  \n",
       "17          0.5    2.0  \n",
       "18          0.5    2.0  \n",
       "19          0.5    2.0  \n",
       "20          0.5    2.0  \n",
       "21          0.5    2.0  \n",
       "22          0.5    2.0  \n",
       "23          0.5    1.0  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,test_data = read_data(dataset_path)\n",
    "train_x,train_y = divide_xy(train_data)\n",
    "test_x , test_y = divide_xy(test_data)\n",
    "\n",
    "labeled_data,unlabeled_data , rate_p,tuple_list_pn = split_trainset(train_data)\n",
    "\n",
    "labeled_data\n",
    "# unlabeled_data.iloc[0]\n",
    "labeled_data.append(unlabeled_data.iloc[0],ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
